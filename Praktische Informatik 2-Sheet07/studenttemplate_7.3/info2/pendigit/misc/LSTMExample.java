package info2.pendigit.misc;


import de.jannlab.Net;
import de.jannlab.generator.GenerateNetworks;


/**
 * This class contains some example code showing how 
 * to create an LSTM instance (using the JANNLab library),
 * how to load the pretrained weights from a file, and how to
 * use the network to generate an output given an input.
 * This code below is all you need to sufficiently implement
 * the class LSTMClassifier.
 * 
 * For a general understanding of RNNs: 
 * http://karpathy.github.io/2015/05/21/rnn-effectiveness
 * 
 * For a deeper insight into the field of RNNs/LSTMs:
 * https://www.cs.toronto.edu/~graves/preprint.pdf
 * 
 * @author Sebastian Otte
 */
public class LSTMExample {
    
    public static void main(String[] args) {
        final int inputSize = 3;
        final int outputSize = 10;
        //
        // This is a descriptor for an LSTM network
        // with given input size (3) and output size (10).
        // It is interpreted by the library to assemble 
        // the corresponding network instance.
        // 
        // Note: Do not change anything here. Only a small
        // change of one of the values will cause the 
        // pretrained weights to mismatch the network structure.
        //
        // The var call substitutes the place holders #1 and #2 within
        // the descriptor String with inputSize and outputSize, respectively.
        //
        final String netDescriptor = LSTMTools.var(
            "LSTM-#1-tanh32-softmax#2", inputSize, outputSize
        );
        System.out.println(netDescriptor);
        //
        // Generates the network from descriptor.
        //
        final Net net = GenerateNetworks.generateNet(netDescriptor);
        System.out.println("number of weights: " + net.getWeightsNum());
        //
        // Currently, the network is dumb and knows essentially nothing.
        // Hence, we have to put some knowledge into the network, which
        // can be done by loading some pretrained weights into the network.
        // The next two lines turn our dump network into a nice handwriting
        // recognizer.
        //
        final double[] weights = LSTMTools.loadWeights(
            "info2/pendigit/resources/" + netDescriptor + ".weights.gz"
        );
        net.writeWeights(weights, 0);
        //
        // Now the network can be used.
        //
        // Communicating with the network is done via double arrays.
        // These arrays have to match the input/output size of the network.
        //
        final double[] input = new double[inputSize];
        final double[] output = new double[outputSize];
        //
        // Assuming that the input contains some useful data, we can feed
        // input into the network via its input method (the second argument
        // is used as an additional offset here --- just leave it 0 and 
        // ignore it).
        //
        // In this exercise the input consists of (i) the current x position 
        // of the pen, (ii) the current y position of the pen, and (iii) an 
        // onset value that
        // is 1.0 at the very first point of every stroke and 0.0 otherwise.
        //
        net.input(input, 0);
        //
        // Now, we can let the network do its magic by invoking its compute 
        // method. The method basically performs the entire network activity
        // propagation process, which includes input processing, neuron to 
        // neuron communication, and output processing. The network output
        // is computed based on the current input as well as the previous 
        // state of network, which is essentially information that the network
        // can remember from previous inputs (an RNN is able to remember things
        // over time).
        //
        net.compute();
        //
        // The current output can be fetched using the output method. The 
        // output of the network is stored in the output array. The array
        // will contain values within the range [0,1] representing a probability
        // distribution of the 10 classes (the digits 0 ... 9). The higher the
        // particular value is, the more the network is convinced that the
        // respective digit is currently drawn. However, this evaluation is 
        // already implemented within the GUI classes.
        // 
        net.output(output, 0);
        //
        // With every new data point being generated by the pen board, we can
        // repeat the input -> compute -> output scheme, which update our network
        // state and our prediction as well.
        //
        // ...
        // ...
        //
        // Once we have reached the end of digit sequence (which is indicated 
        // by the GUI), we have to erase the internal state of the network's
        // reset method. Note that the reset will cause the network to forget
        // what it has seen previously. After that we are ready to start 
        // detecting the next digit.
        //
        net.reset();
    }

}